{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-marina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ETL dependencies\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import regular expressions library\n",
    "import re\n",
    "\n",
    "# Import sqlalchemy module\n",
    "!pip install sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#Import db_password\n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path (absolute) to import Wiki JSON file\n",
    "file_dir ='C://Users/carly/OneDrive/Desktop/data_bootcamp/analysis_projects/Movies_ETL/Resources/'\n",
    "# Open file in directory\n",
    "f'{file_dir}wikipedia.movies.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Wiki JSON file and save data to a new variable\n",
    "with open(f'{file_dir}/wikipedia.movies.json', mode='r') as file:\n",
    "    wiki_movies_raw =json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of records pulled in\n",
    "len(wiki_movies_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 records\n",
    "wiki_movies_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 5 records\n",
    "wiki_movies_raw[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some records in the middle\n",
    "wiki_movies_raw[3600:3605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Kaggle data and pull files into Pandas Dataframes directly\n",
    "kaggle_metadata = pd.read_csv(f'{file_dir}movies_metadata.csv', low_memory=False)\n",
    "ratings = pd.read_csv(f'{file_dir}ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Dataframes (kaggle_metadata)\n",
    "kaggle_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_metadata.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect column datatypes (kaggle_metadata)\n",
    "kaggle_metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Dataframes (ratings)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect column datatypes (ratings)\n",
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert wiki_movies_raw into a DataFrame\n",
    "wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert wiki_movies_df.columns to a list\n",
    "wiki_movies_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute list comprehension to filter data for only movies with a director and an IMDb link\n",
    "wiki_movies = [movie for movie in wiki_movies_raw\n",
    "                         if ('Director' in movie or 'Directed by' in movie)\n",
    "                             and 'imdb_link' in movie]\n",
    "# See how many movies are in intermediate variable, wiki_movies\n",
    "len(wiki_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a DataFrame with wiki_movies to reinspect modified data\n",
    "wiki_movies_filtered = pd.DataFrame(wiki_movies)\n",
    "wiki_movies_filtered.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make nondestructive edits: Inspect\n",
    "wiki_movies_filtered.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add filter for 'No. of episodes' to our list comprehension to remove TV shows from data \n",
    "wiki_movies = [movie for movie in wiki_movies_raw\n",
    "                              if ('Director' in movie or 'Directed by' in movie)\n",
    "                                  and 'imdb_link' in movie\n",
    "                                  and 'No. of episodes' not in movie]\n",
    "len(wiki_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-meeting",
   "metadata": {},
   "source": [
    "# Revisit Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global and local variable values example\n",
    "x = 'global value'\n",
    "\n",
    "def foo():\n",
    "    x = 'local value'\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Be careful of passing mutable obects like a dictionary or list as parameters to function\n",
    "my_list = [1, 2, 3]\n",
    "def append_four(x):\n",
    "    x.append(4)\n",
    "\n",
    "append_four(my_list)\n",
    "print(my_list) # bc my_list is mutable, global variable is not protected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lamda Functions\n",
    "square = lambda x: x * x\n",
    "square(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create skelton of dict () function to make copy of movie\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie)  #Create non-desctructive copy\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect languages in wiki_movies\n",
    "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit url of two movies returned in results\n",
    "wiki_movies_df[wiki_movies_df['Arabic'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-mistake",
   "metadata": {},
   "source": [
    "# __SKILL DRILL__: \n",
    "   ## Go through each column, one by one, and determine which columns hold alternate titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort column names and display column names in alphabetical order\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df[wiki_movies_df[ 'Alias'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df[wiki_movies_df[ 'Also known as'].notnull()]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df[wiki_movies_df['Polish'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKILL DRILL: Implement logic steps and add in code to handle the alternatuve titles.\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie)  # create a non-destructive copy\n",
    "    alt_titles = {}   # Step 1: Make an empty dict to hold all alt_titles\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese',\n",
    "                    'French','Hangul','Hebrew','Hepburn','Japanese',\n",
    "                    'Literally','Mandarin','McCune–Reischauer','Original title',\n",
    "                    'Polish','Revised Romanization','Romanized','Russian',\n",
    "                    'Simplified','Traditional','Yiddish']:  # Step 2: Loop through a list of all alt_titles.keys()\n",
    "        if key in movie:                                               # Step 2a: Check if current key exists in movie object\n",
    "            alt_titles[key] = movie[key]                     # Step 2b: If so, remove the key-value pair and add to alt_titles = {}                 \n",
    "            movie.pop(key)              \n",
    "    if len(alt_titles) > 0:                                          # Step 3: After looping thru every key, add alt_titles dict to movie object\n",
    "        movie['alt_titles'] = alt_titles\n",
    "    \n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of cleaned movies with a list comprehension:\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "# Set wiki_movies_df to be the DataFrame created from clean_movies.\n",
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "# Print out a list of the columns.\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: Multiple columns with slightly different names but the same data (\"Directed by\" and \"Director\")\n",
    "# PLAN: Need to consolidate columns with same data into one column.\n",
    "        # Use pop() method to change name of a dict key because it returns the value from the removed key-value pair.\n",
    "        # Check if the key exists in a given movie record \n",
    "        # Make a small function inside clean_movie() to help.\n",
    "        # Name functions as verbs and be explicit: write out full words so ETL process is easier to follow\n",
    "    \n",
    "# New function name : change_column_name\n",
    "def change_column_name(old_name, new_name):\n",
    "     if old_name in movie:\n",
    "        movie[new_name] = movie.pop(old_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    alt_titles = {}\n",
    "    # combine alternate titles into one list\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune-Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "\n",
    "    # EXECUTE: merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE: Rerun our clean_movies list comprehension to clean wiki_movies and recreate wiki_movies_df\n",
    "clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "sorted(wiki_movies_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-screening",
   "metadata": {},
   "source": [
    "# 8.3.7 - Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the IMDb ID\n",
    "wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "print(len(wiki_movies_df))\n",
    "wiki_movies_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "print(len(wiki_movies_df))\n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-disease",
   "metadata": {},
   "source": [
    "# Remove Mostly Null Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of null values for each column in wiki_movies_df\n",
    "[[column, wiki_movies_df[column].isnull().sum()] for column in wiki_movies_df.columns]\n",
    "\n",
    "# FINDINGS: About half of the columns have more than 6000 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE: Make list of columns that have < 90% null values to trim down dataset\n",
    "[column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns to keep from Pandas DataFrame.\n",
    "wiki_columns_to_keep = [column for column in wiki_movies_df.columns if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "\n",
    "# Inspect DataFrame - reduced 191 messy columns down to 21 useful, data-filled columns\n",
    "wiki_movies_df.head()\n",
    "\n",
    "# IMPORTANT: \"alt_titles\" column created earlier is deleted \n",
    "# Possible that all alt_titles.columns had < 10% non-null values, but collectively had enough data to keep.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-excellence",
   "metadata": {},
   "source": [
    "# 8.3.8 Make a Plan to Convert and Parse the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: Identify which columns need to be converted\n",
    "wiki_movies_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Box office' : object to numeric\n",
    "# 'Budget' : object to numeric\n",
    "# 'Release date' : object to numeric\n",
    "# 'Running time': object to numeric\n",
    "\n",
    "print(wiki_movies_df['Box office'])\n",
    "print(wiki_movies_df['Budget'])\n",
    "print(wiki_movies_df['Release date'])\n",
    "print(wiki_movies_df['Release date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-actress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with box office data\n",
    "box_office = wiki_movies_df['Box office'].dropna()\n",
    "len(box_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE: Is 5,485 movies with box office data reasonable? - YES\n",
    "[[column, wiki_movies_df[column].count()] for column in wiki_movies_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's about 5,500 movies out of 7,000, which is a little more than three-quarters. \n",
    "# Box office data is reported by multiple sources, and we'd expect some percentage of them to not have reliable box office numbers, \n",
    "# or for smaller indie films to not have any box office numbers published at all. \n",
    "# Twenty-five percent would mean the bottom quartile of movies has no box office data, which seems a little high, \n",
    "# but for every movie missing box office data, there are a little more than three movies that do have box office data. \n",
    "# Also, 5,500 is still a good number of movies to perform analysis on (more than 180 movies per year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a is_not_a_string() function:\n",
    "def is_not_a_string(x):\n",
    "    return type(x) != str\n",
    "\n",
    "box_office[box_office.map(is_not_a_string)] # Want a stripped-down, one-line way of writing/calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REWIND: Utilize anonymous lambda --create right inside the map() call\n",
    "lambda x: type(x) != str   # Equivlant to: ' def is_not_a_string(x)'\n",
    "\n",
    "# Update map() call to use labda function directly:\n",
    "box_office[box_office.map(lambda x: type(x) != str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a separator string and THEN call the join() method on it. Sytnax:\n",
    "some_list = ['One', 'Two', 'Three']\n",
    "'Mississippi'.join(some_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a simple space as the joining character. Apply join() ONLY when data points are lists.\n",
    "box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "box_office"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geographic-canada",
   "metadata": {},
   "source": [
    "# 8.3.9 - Write Regular Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cheat sheet examples here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-monkey",
   "metadata": {},
   "source": [
    "# 8.3.10 = Parse the Box Office Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box office data written in two forms. Build a regular expression for each form:\n",
    "# \"$123.4 million\" (or billion) and \"$123,456,789\"\n",
    "\n",
    "# PLAN: Create the First Form \"$123.4 million/billion\" - pattern match string will include:\n",
    "# 1. A dollar sign - (\\$)\n",
    "\"\\$\"\n",
    "# 2. An arbitrary (but non-zero) number of digits - (\\d+)\n",
    "\"\\$\\d+\"\n",
    " # 3. An optional decimal point - (\\.?)\n",
    "\"\\$\\d+\\.?\"\n",
    " # 4. An arbitrary (but possibly zero) number of more digits (\\d*)\n",
    "\"$\\d+\\.?\\d*\"\n",
    " # 5. A space (maybe more than one) (\\s*)\n",
    "\"$\\d+\\.?\\d*\\s*\"\n",
    " # 6. The word \"million\" or \"billion\" - \"[mb]illion\"\n",
    "\"$\\d+\\.?\\d*\\s*[mb]illion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN: Create a variable 'form_one' and set it equal to finished regular expression string\n",
    "form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: Use the 'str.contains()' method on 'box_office'. \n",
    "# Add 'flags' arguent to ignore case of letters and set it =re.IGNORECASE\n",
    "# Call the sum() method to count total number that return TRUE\n",
    "\n",
    "box_office.str.contains(form_one, flags=re.IGNORECASE).sum() \n",
    "# FINDING: There are 3,896 box office values that match the form ''$123.4 million/billion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-circumstances",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN: Creare the Second Form - \"$123,456,789\"  - pattern match string includes:\n",
    "# 1. A dollar sign (\\$)\n",
    "\"\\$\"\n",
    "# 2. A group of one to three digits - (\\d{1,3})\n",
    "\"\\$\\d{1,3}\"\n",
    "# 3. At least one group starting with a comma and followed by exactly three digits - (\"?:,\\f{3})+\")\n",
    "    # 3a. \",\\d{3}\" - match a comma exactly three digits\n",
    "    # 3b. \"(,\\d{3}+)\" - match any repetition of that group, put it inside (), and then put a plus sign after ()\n",
    "    # 3c. \"(?:,\\d{3})+\" - last modification specifies that this is a non-capturing group by: \"(?:)\"\n",
    "        # NOTE:  Use of \"?:\" is not strictly necessary, but eliminates an unwanted warning message in Jupyter Notebook\n",
    "\"\\$\\d{1,3}(?:,\\d{3})+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT:\n",
    "form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "box_office.str.contains(form_two, flags=re.IGNORECASE).sum()\n",
    "# FINDING: There are 1,544 box office values that match the form \"$123,456,789.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-tolerance",
   "metadata": {},
   "source": [
    "## Compare Values in Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two Boolean Series - INSPECT box_office to see if any valyes are described by both.\n",
    "matches_form_one = box_office.str.contains(form_one, flags=re.IGNORECASE)\n",
    "matches_form_two = box_office.str.contains(form_two, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will throw an error! - 'ValueError' w/ explanation \"The truth value of a Series is ambiguous.\"\n",
    "# box_office[(not matches_form_one) and (not matches_form_two)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas has element-wise logical operators:\n",
    "    # '~' = element-wise negation (\"not\") operator\n",
    "    # '&' = element_wise logical \"and\" is the ampersand\n",
    "    # '|' = element_wise \"or\" is the pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-prime",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "box_office[~matches_form_one & ~matches_form_two]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve the count of non-matches\n",
    "len(box_office[~matches_form_one & ~matches_form_two])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-obligation",
   "metadata": {},
   "source": [
    "## Fix Pattern Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN: We can fix pattern matches to capture more values by addressing these issues:\n",
    "# 1. Some values have spaces in between the dollar sign and the number. - Just add '\\s*' after the $\n",
    "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illion'\n",
    "form_two = r'\\$\\s*\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "# 2. Some values use a period as a thousands separator, not a comma. - (?:[,\\.]) *form_two only\n",
    "    # 2a. Change form_two to allow for either a comma or a period as a thoudsands separator:\n",
    "form_two = r'\\$\\s*d{1,3}(?:[,\\.]\\d{3})+'\n",
    "    # 2b. Must add a negative lookahead group (?!) that looks ahead for \"million\"/\"billion\" -> after number & rejects match\n",
    "    # 2c. Don't forget the spaces in between \n",
    "form_two = r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)'\n",
    "\n",
    "# 3. Some values are given as a range:\n",
    "    # 3a. Search for any string that begins with '$' and ends with ''---\"\"\n",
    "    # 3b. Then replace hyphen w/ '$' using 'replace()'\n",
    "        # 3c. The first argument in replace() = substring that will be replaced\n",
    "            # 3d. Use regular expressions in the first arg by sending the paramter 'regex=True'\n",
    "        # 3e The second argument = string to replace with\n",
    "box_office = box_office.str.replace(r'\\$.*[[-—–]](?![a-z])', '$', regex=True)\n",
    "\n",
    "# 4. \"Million\" is sometimes misspelled as \"milion.\" - Make the second \"i\" optional in match string with a question mark:\n",
    "form_one = r'\\$\\s*\\d+\\.?\\d*\\s*[mb]illi?on'\n",
    "\n",
    "# NOTE: Remainder of box office values make up such a small % of dataset and would require too much time/effort to parse correctly, so we just ignore them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-fellow",
   "metadata": {},
   "source": [
    "## Extract and Conver the Box Office Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE: Make a regular expression, using f-string, that matches either form_one or form_two\n",
    "box_office.str.extract(f'({form_one} | {form_two})')\n",
    "box_office.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dollars(s):\n",
    "    # if s is not a string, return NaN\n",
    "    if type(s) != str:\n",
    "        return np.nan\n",
    "\n",
    "    # if input is of the form $###.# million\n",
    "    if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*milli?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" million\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a million\n",
    "        value = float(s) * 10**6\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###.# billion\n",
    "    elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billi?on', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and \" billion\"\n",
    "        s = re.sub('\\$|\\s|[a-zA-Z]','', s)\n",
    "\n",
    "        # convert to float and multiply by a billion\n",
    "        value = float(s) * 10**9\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # if input is of the form $###,###,###\n",
    "    elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.IGNORECASE):\n",
    "\n",
    "        # remove dollar sign and commas\n",
    "        s = re.sub('\\$|,','', s)\n",
    "\n",
    "        # convert to float\n",
    "        value = float(s)\n",
    "\n",
    "        # return value\n",
    "        return value\n",
    "\n",
    "    # otherwise, return NaN\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, extract the values from 'box_office using 'str.exact'\n",
    "# Then, apply parse_dollars to the first column returned in the DataFrame:\n",
    "wiki_movies_df['box_office'] = box_office.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "wiki_movies_df['box_office']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.drop('Box office', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-wiring",
   "metadata": {},
   "source": [
    "# 8.3.11 - Parse Budget Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create budget variable\n",
    "budget = wiki_movies_df['Budget'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert any lists to strings:\n",
    "budget = budget.map(lambda x: ' '.join(x) if type(x) == list else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any values between a dollar sign and a hyphen (for budgets given in ranges)\n",
    "budget = budget.str.replace(r'\\$.*[-—–](?![a-z])', '$', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: Parse the box office data, and apply them without modifications to budget data. \n",
    "# Then, look at what's left.\n",
    "matches_form_one = budget.str.contains(form_one, flags=re.IGNORECASE)\n",
    "matches_form_two = budget.str.contains(form_two, flags=re.IGNORECASE)\n",
    "budget[~matches_form_one & ~matches_form_two]                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN: New issue with budget data: citation references (numbers in '[]')\n",
    "\"\\[d+\\]\" # This regex will match a number within square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-caribbean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the citation references\n",
    "budget = budget.str.replace(r'\\[\\d+\\]\\s*', '')\n",
    "print(budget[~matches_form_one & ~matches_form_two])\n",
    "print(len(budget[~matches_form_one & ~matches_form_two]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE:  Not worth parsing the remaining 38 (with a majority being foreign currencies).\n",
    "len(budget) \n",
    "# 30/4,700 <= 1% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE: Parse the budget values\n",
    "wiki_movies_df['budget'] = budget.str.extract(f'({form_one}|{form_two})', flags=re.IGNORECASE)[0].apply(parse_dollars)\n",
    "# Drop the original Budget column\n",
    "wiki_movies_df.drop('Budget', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-proportion",
   "metadata": {},
   "source": [
    "## Parse Release Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to strings and make a varable to hold the non-null values of Release data\n",
    "release_date = wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "release_date.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKILL DRILL:  Parse the following forms:\n",
    "\n",
    "# Full month name, one- to two-digit day, four-digit year (i.e., January 1, 2000)\n",
    "date_form_one = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]\\d,\\s\\d{4}'    \n",
    "    \n",
    "# Four-digit year, two-digit month, two-digit day, with any separator (i.e., 2000-01-01)\n",
    "date_form_two = r'\\d{4}.[01]\\d.[123]\\d'\n",
    "    \n",
    " # Full month name, four-digit year (i.e., January 2000)\n",
    "date_form_three = r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    \n",
    "# Four-digit year\n",
    "date_form_four = r'\\d{4}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dates with:\n",
    "release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the built-in 'to_datetime()' method in Pandas to parse the dates\n",
    "wiki_movies_df['release_date'] = pd.to_datetime(release_date.str.extract(f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-gambling",
   "metadata": {},
   "source": [
    "## Parse Running Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to strings and make a varable to hold the non-null values of 'Running time'\n",
    "running_time = wiki_movies_df['Running time'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "running_time.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: See how many running times look exactly like \"100 minutes\" by using string boundaries.\n",
    "running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: See what the remaining 366 entries look like.\n",
    "running_time[running_time.str.contains(r'^\\d*\\s*minutes$', flags=re.IGNORECASE) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept other abbreviations of \"minutes\" by only searching up to the letter \"m\"\n",
    "running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the remainging 17 data points.\n",
    "running_time[running_time.str.contains(r'^\\d*\\s*m', flags=re.IGNORECASE) != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question:\n",
    "# What is the new regular expression that relaxes the condition of patterns starting at the beginning of the string?\n",
    "r'\\d*\\s*m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN: We can match all of the hour+ minute patterns with one regular expression pattern:\n",
    "# Start with one or more digits\n",
    "\"\\d+\"\n",
    "# Have an optional space after the digit and before the letter \"h\"\n",
    "\"\\d+\\s*h\"\n",
    "# Capture all possible abbrev of \"hour(s)\" - Make every letter in \"hours\" optional except the \"h\"\n",
    "\"\\d+\\s*ho?u?r?s?\"\n",
    "# Have an optional space after the \"hours\" marker\n",
    "\"\\d+\\s*ho?u?r?s?\\s*\"\n",
    "# Have an optional number of digits for minues\n",
    "\"\\d+\\s*ho?u?r?s?\\s*\\d*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-scope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE: - Only want to extract digits and allowfor both possible patterns\n",
    "# Add capture groups around the '\\d' instances and add an alternating character\n",
    "running_time_extract = running_time.str.extract(r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "running_time_extract.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE: convert new DataFrame dtypes from strings to numberic\n",
    "    # Use 'to_numeric()' method and set the errors arugment to 'coerce'\n",
    "    # 'coerce' -> turn the empty strings into NaN\n",
    "    # Then use fillna() to change all NaNs to zeros\n",
    "running_time_extract = running_time_extract.apply(lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hour and minute capture groups to minutes:\n",
    "    # if pure minutes capture group is zero\n",
    "wiki_movies_df['running_time'] = running_time_extract.apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_movies_df.drop('Running time', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-branch",
   "metadata": {},
   "source": [
    "# 8.3.12 - Clean the Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inital look at the movie metadata\n",
    "kaggle_metadata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all values of \"adult\" and \"video\" columns are True or False\n",
    "kaggle_metadata['adult'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Bad Data\n",
    "kaggle_metadata[~kaggle_metadata['adult'].isin(['True','False'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAUSE: Only keep where 'adult' is False, then drop the \"adult\" column\n",
    "kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop('adult',axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-person",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inspect the video column values: \n",
    "kaggle_metadata['video'].value_counts() # FINDING: Only True/False values, so will be easy to conert 'video'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Data Types\n",
    "kaggle_metadata['video'] == 'True' # Creaes the Boolean column we want. \n",
    "kaggle_metadata['video'] = kaggle_metadata['video'] == 'True' # Assign back to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLAN: Use 'to_numeric()' for numeric columns. Set errors= argugment to 'raise'\n",
    "# Convert Data Types\n",
    "kaggle_metadata['video'] == 'True' # Creaes the Boolean column we want. \n",
    "kaggle_metadata['video'] = kaggle_metadata['video'] == 'True' # Assign back to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'release_date' to datetime with Pandas to_datetime()\n",
    "kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-magnitude",
   "metadata": {},
   "source": [
    "## Reasonability Checks on Ratings Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect ratings data with info() method on the DataFrame.\n",
    "# Need to set the null_counts option to True--because so many rows in dataset\n",
    "ratings.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unix epoch - specify in 'to_datetime()' that this is origin and time unit is seconds\n",
    "pd.to_datetime(ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign output to the timestamp column\n",
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSPECT: Find Summary statistics of actual ratings using histogram\n",
    "# to check for glaring errors\n",
    "pd.options.display.float_format = '{:20,.2f}'.format\n",
    "ratings['rating'].plot(kind='hist')\n",
    "ratings['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-surgeon",
   "metadata": {},
   "source": [
    "# 8..4.1 - Merge Wikipedia and Kaggle Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a list of columns to identify redundencies. Use 'suffixes' parameter for easy identification \n",
    "movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id', suffixes=['_wiki','_kaggle'])\n",
    "print(movies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Competing data:\n",
    "# Wiki                     Movielens                Resolution\n",
    "#--------------------------------------------------------------------------\n",
    "# title_wiki               title_kaggle\n",
    "# running_time             runtime\n",
    "# budget_wiki              budget_kaggle\n",
    "# box_office               revenue\n",
    "# release_date_wiki        release_date_kaggle\n",
    "# Language                 original_language\n",
    "# Production company(s)    production_companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-directory",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-cleveland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some of titles\n",
    "movies_df[['title_wiki','title_kaggle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows where titles don't match:\n",
    "movies_df[movies_df['title_wiki'] != movies_df['title_kaggle']][['title_wiki','title_kaggle']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show any rows where title_kaggle is empty\n",
    "movies_df[(movies_df['title_kaggle'] == '') | (movies_df['title_kaggle'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No columns returned, so we can drop Wiki titles:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-rolling",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at running_time vs runtime with scatter plots--great way to visualize how similar columns are to each other .\n",
    "# CAUTION: Need to fill missing values with zero, and THEN make scatter plot\n",
    "movies_df.fillna(0).plot(x='running_time', y='runtime', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-sport",
   "metadata": {},
   "source": [
    "## Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.fillna(0).plot(x='budget_wiki',y='budget_kaggle', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-territory",
   "metadata": {},
   "source": [
    "## Box Office"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.fillna(0).plot(x='box_office', y='revenue', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at scatter plot for everything less than $1 billion in box_office\n",
    "movies_df.fillna(0)[movies_df['box_office'] < 10**9].plot(x='box_office', y='revenue', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-english",
   "metadata": {},
   "source": [
    "## Release Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tricky workaround to plot release data--because scatter plots only work on numeric data\n",
    "    # 1. Use regular line plot and\n",
    "    # 2. Change style to only put dots by adding 'style='.' to the plot() method\n",
    "movies_df[['release_date_wiki','release_date_kaggle']].plot(x='release_date_wiki', y='release_date_kaggle', style='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate wild outlier around 2006.\n",
    "movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'The Holiday' in wiki data got merged with 'From Here to Eternity'\n",
    "# Drop that row from data frame:\n",
    "\n",
    "# Get index of that row:\n",
    "movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index\n",
    "\n",
    "# Drop row:\n",
    "movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & (movies_df['release_date_kaggle'] < '1965-01-01')].index)\n",
    "\n",
    "# See if there are any null values:\n",
    "movies_df[movies_df['release_date_wiki'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-animal",
   "metadata": {},
   "source": [
    "# Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists in 'Language' to tuples so that value_counts() method will work.\n",
    "movies_df['Language'].apply(lambda x: tuple(x) if type(x) == list else x).value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run value_counts() on Kaggle data--no lists in data\n",
    "movies_df['original_language'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-obligation",
   "metadata": {},
   "source": [
    "## Production Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect sample of dataset\n",
    "movies_df[['Production company(s)','production_companies']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-tablet",
   "metadata": {},
   "source": [
    "Wikipedia\tKaggle\tResolution\n",
    "title_wiki\ttitle_kaggle\tDrop Wikipedia.\n",
    "running_time\truntime\tKeep Kaggle; fill in zeros with Wikipedia data.\n",
    "budget_wiki\tbudget_kaggle\tKeep Kaggle; fill in zeros with Wikipedia data.\n",
    "box_office\trevenue\tKeep Kaggle; fill in zeros with Wikipedia data.\n",
    "release_date_wiki\trelease_date_kaggle\tDrop Wikipedia.\n",
    "Language\toriginal_language\tDrop Wikipedia.\n",
    "Production company(s)\tproduction_companies\tDrop Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-measurement",
   "metadata": {},
   "source": [
    "## Put it all Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Wiki columns\n",
    "movies_df.drop(columns=['title_wiki','release_date_wiki','Language','Production company(s)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a function that fills in missing data for a column pair and then drops redudant column\n",
    "def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "    df[kaggle_column] = df.apply(\n",
    "        lambda row: row[wiki_column] if row[kaggle_column] == 0 else row[kaggle_column]\n",
    "        , axis=1)\n",
    "    df.drop(columns=wiki_column, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function for three column pairs to fill in zeros\n",
    "fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns to see if any have only one value. \n",
    "# Convert lists to tuples for value_counts to work\n",
    "for col in movies_df.columns:\n",
    "    lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "    value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "    num_values = len(value_counts)\n",
    "    if num_values == 1:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['video'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reourder columns \n",
    "movies_df = movies_df.loc[:, ['imdb_id','id','title_kaggle','original_title','tagline','belongs_to_collection','url','imdb_link',\n",
    "                       'runtime','budget_kaggle','revenue','release_date_kaggle','popularity','vote_average','vote_count',\n",
    "                       'genres','original_language','overview','spoken_languages','Country',\n",
    "                       'production_companies','production_countries','Distributor',\n",
    "                       'Producer(s)','Director','Starring','Cinematography','Editor(s)','Writer(s)','Composer(s)','Based on'\n",
    "                      ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, rename columns to be consistent.\n",
    "movies_df.rename({'id':'kaggle_id',\n",
    "                  'title_kaggle':'title',\n",
    "                  'url':'wikipedia_url',\n",
    "                  'budget_kaggle':'budget',\n",
    "                  'release_date_kaggle':'release_date',\n",
    "                  'Country':'country',\n",
    "                  'Distributor':'distributor',\n",
    "                  'Producer(s)':'producers',\n",
    "                  'Director':'director',\n",
    "                  'Starring':'starring',\n",
    "                  'Cinematography':'cinematography',\n",
    "                  'Editor(s)':'editors',\n",
    "                  'Writer(s)':'writers',\n",
    "                  'Composer(s)':'composers',\n",
    "                  'Based on':'based_on'\n",
    "                 }, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-debut",
   "metadata": {},
   "source": [
    "# 8.4.2 - Transform and Merge Rating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the \"userid\" column to \"count\"\n",
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot data so that movieId is the index, columns will be rating values, and row will be counts for each rating value.\n",
    "rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count() \\\n",
    "                .rename({'userId':'count'}, axis=1) \\\n",
    "                .pivot(index='movieId',columns='rating', values='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend rating_ to each column with list comprehension:\n",
    "rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, merge the rating counts into movies_df\n",
    "# We want to keep all data values in movies_df, whether it has ratings data or not\n",
    "\n",
    "# Use left merge\n",
    "movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-passenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, fill in missing values with zeros\n",
    "movies_with_ratings_df[rating_counts.columns] = movies_with_ratings_df[rating_counts.columns].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-conditions",
   "metadata": {},
   "source": [
    "# 8.5.1 - Connect Pandas and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Database Engine\n",
    "# \"postgres://[user]:[password]@[location]:[port]/[database]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-shuttle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local server connection string\n",
    "db_string = f\"postgres://postgres:{db_password}@127.0.0.1:5432/movie_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-harvard",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create database engine\n",
    "engine = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Movie Data\n",
    "movies_df.to_sql(name='movies', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Ratings Data\n",
    "\n",
    "# STOP: Do not run this yet!\n",
    "# for data in pd.read_csv(f'{file_dir}ratings.csv', chunksize=1000000):\n",
    "    # data.to_sql(name='ratings', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Print Number of Imported Rows\n",
    "\n",
    "# create a variable for the number of rows imported\n",
    "rows_imported = 0\n",
    "for data in pd.read_csv(f'{file_dir}/ratings.csv', chunksize=1000000):\n",
    "\n",
    "    # print out the range of rows that are being imported\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "\n",
    "    # increment the number of rows imported by the size of 'data'\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    # print that the rows have finished importing\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Print Elapsed Time\n",
    "\n",
    "# get the start_time from time.time()\n",
    "rows_imported = 0\n",
    "# get the start_time from time.time()\n",
    "start_time = time.time()\n",
    "for data in pd.read_csv(f'{file_dir}/ratings.csv', chunksize=1000000):\n",
    "    print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "    data.to_sql(name='ratings', con=engine, if_exists='append')\n",
    "    rows_imported += len(data)\n",
    "\n",
    "    # add elapsed time to final print out\n",
    "    print(f'Done. {time.time() - start_time} total seconds elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-negotiation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-suspension",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-briefing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
